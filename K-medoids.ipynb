{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "057f5d54-f785-4d04-879a-55ffc52c9c34",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import interp1d\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2225ed-bf7a-459a-85f5-309a5f3982e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn_extra.cluster import KMedoids\n",
    "from scipy.stats import wasserstein_distance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b6287de-9a91-4e3a-9d9b-1472ea8acece",
   "metadata": {},
   "source": [
    "# Import and Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5cd9e56-3f0b-417e-891c-f60ef4da0fdc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('E:\\Documents\\Google Drive\\Eskwelabs\\Sprint 5 - Capstone\\data\\consolidated_csv_01SUAL_G01.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7356b771-414c-42ad-9ff5-f2940d71dd39",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the columns containing price-quantity pairs and timestamps\n",
    "price_columns = [f'PRICE{i}' for i in range(1, 12)]\n",
    "quantity_columns = [f'QUANTITY{i}' for i in range(1, 12)]\n",
    "\n",
    "# specify selected price-quantity columns\n",
    "selected_columns = ['RUN_TIME'] + [price for price in price_columns] + [quantity for quantity in quantity_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56762250-379b-448b-bbd2-3433864ef790",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# Apply the selection to the filtered DataFrame\n",
    "result_df = df[selected_columns]\n",
    "\n",
    "#change Uppercase to lowercase\n",
    "result_df.columns = result_df.columns.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43cf833e-14bd-46ab-b961-371dfad7527a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Convert 'run_time' to datetime with multiple formats\n",
    "result_df['temp_run_time'] = pd.to_datetime(result_df['run_time'], errors='coerce', format='%m/%d/%Y %I:%M:%S %p').copy()\n",
    "\n",
    "# Handle the remaining date-only format separately\n",
    "mask_date_only = result_df['temp_run_time'].dt.time == pd.Timestamp('00:00:00').time()\n",
    "result_df['run_time'] = result_df['temp_run_time'].where(mask_date_only, result_df['temp_run_time'].combine_first(pd.to_datetime(result_df['temp_run_time'], errors='coerce', format='%m/%d/%Y')))\n",
    "\n",
    "# Drop the temporary column\n",
    "result_df.drop(columns=['temp_run_time'], inplace=True)\n",
    "\n",
    "# Print the result\n",
    "result_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b037e37-f5e7-4b3b-8bec-f793eec87601",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "starting_index = 6\n",
    "downsampled_df = result_df.iloc[starting_index::12, :].copy()  # Use .copy() to create a copy of the DataFrame\n",
    "downsampled_df.reset_index(drop=True, inplace=True)\n",
    "downsampled_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59fc3dc6-b37e-427e-8d5e-3433542dda36",
   "metadata": {
    "tags": []
   },
   "source": [
    "## FFill NaNs with last Price-Quantity bid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aceb17e7-a114-4edf-9342-50f136d854ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Forward fill from the first non-null value in each row for the price columns\n",
    "downsampled_df.loc[:, 'price1':'price11'] = downsampled_df.loc[:, 'price1':'price11'].apply(lambda row: row.ffill(), axis=1)\n",
    "\n",
    "# Forward fill from the first non-null value in each row for the quantity columns\n",
    "downsampled_df.loc[:, 'quantity1':'quantity11'] = downsampled_df.loc[:, 'quantity1':'quantity11'].apply(lambda row: row.ffill(), axis=1)\n",
    "\n",
    "downsampled_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e62580-8271-40b5-927d-375225acdc1f",
   "metadata": {},
   "source": [
    "## MinMaxScaler on Quantity values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28c611c-1de3-41fb-91f0-dab484a6b656",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Extract only the quantity columns for normalization\n",
    "quantity_columns = [f'quantity{i}' for i in range(1, 12)]\n",
    "\n",
    "# Flatten the DataFrame and extract only quantity columns\n",
    "flattened_quantities = downsampled_df[quantity_columns].values.flatten()\n",
    "\n",
    "# Reshape the flattened quantities to a column vector\n",
    "flattened_quantities = flattened_quantities.reshape(-1, 1)\n",
    "\n",
    "# Use MinMaxScaler on the flattened quantities\n",
    "scaler = MinMaxScaler()\n",
    "scaled_quantities = scaler.fit_transform(flattened_quantities)\n",
    "\n",
    "# Reshape the scaled quantities to match the original DataFrame shape\n",
    "scaled_quantities = scaled_quantities.reshape(downsampled_df[quantity_columns].shape)\n",
    "\n",
    "# Update the DataFrame with the scaled values\n",
    "downsampled_df.loc[:, quantity_columns] = scaled_quantities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0273b51-7241-4863-8843-616b35be20ea",
   "metadata": {},
   "source": [
    "## Filter df for only 2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edae6d9c-dfd2-4fc4-9f34-a58d6287ebbb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Filter rows within the year 2022\n",
    "df_2022 = downsampled_df[(downsampled_df['run_time'] >= '2022-01-01') & (downsampled_df['run_time'] < '2023-01-01')]\n",
    "\n",
    "# Reset index\n",
    "df_2022 = df_2022.reset_index(drop=True)\n",
    "df_2022"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d91cb7-2eae-43b6-8c4a-422a51f3351a",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e37ebd7-4f6c-4f56-b8aa-13dc15ac8c45",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_2022.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa39d486-9bb8-46b8-9fa2-e3fd49bc86db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_2022.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c671186b-d74e-4a8a-959e-825fc6b61475",
   "metadata": {},
   "source": [
    "## Check for NaNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d056c92-9738-4c44-9064-0a3c5446487c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "missing_values = df_2022.isnull().sum()\n",
    "print(\"Missing Values:\")\n",
    "print(missing_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9495ffd2-083a-4ccc-8362-376ff8ab263d",
   "metadata": {},
   "source": [
    "## Visualize with Histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c281859-31f3-4cb5-858e-18e0060cf3bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Extract prices from df_2022\n",
    "prices_columns = [f'price{i}' for i in range(1, 12)]\n",
    "prices = df_2022[prices_columns].values.flatten()\n",
    "\n",
    "# Plot histogram\n",
    "plt.hist(prices, bins=20, color='blue', alpha=0.7)\n",
    "plt.xlabel('Prices')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Prices')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a518feb-088c-4e5f-acc3-6a15390acc30",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Extract quantities from df_2022\n",
    "quantities_columns = [f'quantity{i}' for i in range(1, 12)]\n",
    "quantities = df_2022[quantities_columns].values.flatten()\n",
    "\n",
    "# Plot histogram\n",
    "plt.hist(quantities, bins=20, color='green', alpha=0.7)\n",
    "plt.xlabel('Quantities')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Quantities')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73bf4ffe-cdcb-4343-9a79-09d961c8e679",
   "metadata": {},
   "source": [
    "# K-medoids on subset of 2022 data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c031c6-6ebf-4a17-9ccc-2af5e3e1cfd6",
   "metadata": {},
   "source": [
    "## Re-shape df into array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fda2ac3-0162-4eac-bab4-ff13f80cb179",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Select subset of df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee63325a-b7b7-4da7-b89e-baa808fb9758",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Select only the first 100 entries from df_2022\n",
    "df_subset = df_2022.head(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1844824-285c-43d6-93cb-9159fd71a186",
   "metadata": {},
   "source": [
    "#### Test plot random bid curves from df_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778e3bac-8e67-4b20-9e02-973c60ee0a3b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Test Plot random indices from subset df\n",
    "# Randomly select 10 indices\n",
    "random_indices = df_subset.sample(n=10).index\n",
    "\n",
    "# Extract prices and cumulative quantities for the randomly selected indices\n",
    "selected_prices = df_subset.loc[random_indices, 'price1':'price11'].values\n",
    "selected_cumulative_quantities = df_subset.loc[random_indices, 'quantity1':'quantity11'].values\n",
    "\n",
    "# Plotting the selected step-wise bid curves\n",
    "for i, idx in enumerate(random_indices):\n",
    "    cumulative_quantity = selected_cumulative_quantities[i]\n",
    "    price = selected_prices[i]\n",
    "    plt.step(cumulative_quantity, price, where='pre', label=f'Curve {idx}')\n",
    "\n",
    "plt.xlabel('Cumulative Quantity (MW)')\n",
    "plt.ylabel('Price (Peso/Megawatt-hr)')\n",
    "plt.title('Randomly Selected Step-wise Bid Curves from df_subset')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7cfa1b0-b97c-4f26-9353-53b4d27d1cb8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Display the subset of df_subset for the randomly selected indices\n",
    "df_subset_random = df_subset.loc[random_indices]\n",
    "df_subset_random.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb976072-30a2-4b37-aa66-8edd30d00a11",
   "metadata": {},
   "source": [
    "#### Make (quantity,price) tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048f7a17-7a8f-492b-91fd-ee3f608c8cc0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get values from columns\n",
    "prices = df_subset[['price1', 'price2', 'price3', 'price4', 'price5', 'price6', 'price7', 'price8', 'price9', 'price10', 'price11']].values\n",
    "quantities = df_subset[['quantity1', 'quantity2', 'quantity3', 'quantity4', 'quantity5', 'quantity6', 'quantity7', 'quantity8', 'quantity9', 'quantity10', 'quantity11']].values\n",
    "\n",
    "# Create list of lists containting (quantity,prices) tuples\n",
    "def create_stepwise_curves(quantities, prices):\n",
    "    step_curves = []\n",
    "    for i in range(len(prices)):\n",
    "        step_curves.append(list(zip(quantities[i], prices[i])))\n",
    "    return step_curves\n",
    "\n",
    "step_curves = create_stepwise_curves(quantities, prices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7059ca96-fbbc-40c2-87de-34626431e336",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Check length of step_curves\n",
    "num_curves = len(step_curves)\n",
    "length_of_first_curve = len(step_curves[0]) if num_curves > 0 else 0\n",
    "\n",
    "print(f\"Number of curves: {num_curves}\")\n",
    "print(f\"Length of the first curve: {length_of_first_curve}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee12ed6d-c359-4047-a4ae-9e79de42cd78",
   "metadata": {},
   "source": [
    "#### Change step_curves into array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da9ed6d-b64f-41e9-80a4-f93ccda032be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Change step_curves into 2D numpy array\n",
    "step_curves_array = np.array(step_curves).reshape(len(step_curves), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ee8daa-c71c-4317-905e-a6b95dae7ac6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Shape of step_curves_array:\", step_curves_array.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e25a5856-2fe0-43aa-91e6-4ea8420b26bf",
   "metadata": {},
   "source": [
    "## Initialize functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc399d96-bba2-4487-b904-b440210331ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn_extra.cluster import KMedoids\n",
    "from scipy.stats import wasserstein_distance\n",
    "from joblib import Parallel, delayed\n",
    "import numpy as np\n",
    "\n",
    "# Function to calculate Wasserstein distance\n",
    "def wasserstein_dist(p1, p2):\n",
    "    return wasserstein_distance(p1, p2)\n",
    "\n",
    "# Function to perform K-medoids clustering\n",
    "def kmedoids_clustering(data, k):\n",
    "    kmedoids = KMedoids(n_clusters=k, metric=wasserstein_dist, random_state=42)\n",
    "    kmedoids.fit(data)\n",
    "    return kmedoids.labels_, kmedoids.cluster_centers_\n",
    "\n",
    "# Function to calculate Separation Threshold\n",
    "def calculate_separation_threshold(labels, centers, separation_threshold, p_ref):\n",
    "    k = len(centers)\n",
    "    s_ref = wasserstein_dist(centers[0], p_ref)  # Assuming P_ref is the first center\n",
    "    s_th = separation_threshold * s_ref\n",
    "    \n",
    "    for i in range(k):\n",
    "        distances_within_cluster = [\n",
    "            wasserstein_dist(step_curves_array[j], centers[i]) \n",
    "            for j in range(len(labels)) if labels[j] == i\n",
    "        ]\n",
    "        rho_i = sum(1 for dist in distances_within_cluster if dist > s_th) / len(distances_within_cluster)\n",
    "\n",
    "        if rho_i > tolerance_rate:\n",
    "            return True\n",
    "\n",
    "    return False\n",
    "\n",
    "# Modify process_chunk to return labels along with result\n",
    "def process_chunk(K, step_curves_array, separation_threshold, tolerance_rate):\n",
    "    labels, centers = kmedoids_clustering(step_curves_array, K)\n",
    "    print(f\"Processed chunk for K={K}: Labels: {labels}, Centers Shape: {np.shape(centers)}\")\n",
    "\n",
    "    # Check for empty clusters\n",
    "    empty_clusters = [i for i, cluster_size in enumerate(np.bincount(labels)) if cluster_size == 0]\n",
    "    if empty_clusters:\n",
    "        print(f\"Warning: Empty clusters found for K={K}, Cluster indices: {empty_clusters}\")\n",
    "\n",
    "    # Print debugging information\n",
    "    print(\"Cluster Centers:\")\n",
    "    print(centers)\n",
    "\n",
    "    result = calculate_separation_threshold(labels, centers, separation_threshold, step_curves_array[0])\n",
    "\n",
    "    return result, labels, centers\n",
    "\n",
    "\n",
    "# Function to find optimal number of clusters\n",
    "def find_optimal_clusters(step_curves_array, K_0, K_max, initial_chunk_size, iterations_within_chunk, separation_threshold, tolerance_rate):\n",
    "    step_curves_array = step_curves_array.astype(np.float32)\n",
    "    \n",
    "    # Initialization\n",
    "    K = K_0\n",
    "    P_ref = step_curves_array[0]  # Using the first curve as a reference\n",
    "\n",
    "    # Initialize the variable to track the optimal number of clusters\n",
    "    optimal_K = K_0  \n",
    "\n",
    "    # Store cluster centers and labels here\n",
    "    centers_list = []  \n",
    "    labels_list = []\n",
    "\n",
    "    while K <= K_max:  \n",
    "        print(f\"Processing chunk for K={K}\")\n",
    "\n",
    "        result_found = False  # Flag to track whether a result was found in the inner loop\n",
    "        # Inside your loop in find_optimal_clusters function\n",
    "        for _ in range(iterations_within_chunk):\n",
    "            chunk_size = min(initial_chunk_size, K_max - K)\n",
    "            chunk_results = list(Parallel(n_jobs=-1)(delayed(process_chunk)(K + i, step_curves_array, separation_threshold, tolerance_rate) for i in range(chunk_size)))\n",
    "\n",
    "            for result, labels, centers in chunk_results:\n",
    "                if result:\n",
    "                    optimal_K = K  # Update the optimal_K variable\n",
    "                    centers_list.append(centers)\n",
    "                    labels_list.append(labels)\n",
    "                    result_found = True\n",
    "                    break\n",
    "\n",
    "            if result_found:\n",
    "                break  # Break out of the inner loop if a result is found\n",
    "                \n",
    "        if result_found:\n",
    "            break  # Break out of the outer loop if a result is found\n",
    "\n",
    "        # Increment K after the chunk is processed\n",
    "        K += chunk_size\n",
    "\n",
    "    # Now optimal_K contains the optimal number of clusters, up to K_max\n",
    "    print(f\"Optimal number of clusters (K): {optimal_K}\")\n",
    "    \n",
    "    # Return the labels_list\n",
    "    return labels_list, centers_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a48b32-857d-4fa4-8610-ba9b47d2ecdc",
   "metadata": {},
   "source": [
    "## Specify parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b847f4-442b-492d-af19-ee60bd821cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "K_0 = 2\n",
    "K_max = 4  # Choose a smaller value for testing\n",
    "separation_threshold = 0.01  # 1% as separation_threshold_ratio, increase if you think clusters should have larger dissimilarity\n",
    "tolerance_rate = 0.05  # original was 0.1, increase if you want to be more strict about considering a cluster as separate\n",
    "\n",
    "# Initial chunk size\n",
    "initial_chunk_size = 5000\n",
    "# Number of iterations within each chunk\n",
    "iterations_within_chunk = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ace2a02-6784-4b1d-89ec-6f4306806f66",
   "metadata": {},
   "source": [
    "## Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a54540be-050b-4a7d-b414-29afd58407be",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Find optimal clusters\n",
    "found_labels_list, found_centers_list = find_optimal_clusters(step_curves_array, K_0, K_max, initial_chunk_size, iterations_within_chunk, separation_threshold, tolerance_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb085dfe-2cd7-4192-8853-3ecabaf5864e",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88462c3f-c18d-4298-844e-01d5d73c5736",
   "metadata": {},
   "source": [
    "### Apply cluster label to df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9d22d5-ead9-4c97-8168-58b9cde77691",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'found_labels_list' is your list of labels after clustering\n",
    "cluster_labels = found_labels_list[0]\n",
    "\n",
    "# Create a copy of the subset to avoid SettingWithCopyWarning\n",
    "df_subset_copy = df_subset.copy()\n",
    "\n",
    "# Add 'cluster_no' column to df_subset_copy using .loc\n",
    "df_subset_copy.loc[:, 'cluster_no'] = cluster_labels.copy()\n",
    "\n",
    "# Now df_subset_copy has the 'cluster_no' column added without warnings\n",
    "df_subset_copy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0523384f-1657-4f0e-a26f-626a76cad71a",
   "metadata": {},
   "source": [
    "### Display cluster medoids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f0db22c-e3f9-4e9b-b2cd-924a603dabea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'centers_list' is your list of cluster centers\n",
    "final_centers = found_centers_list[-1]\n",
    "\n",
    "# Assuming 'final_centers' is your cluster centers\n",
    "num_features = final_centers.shape[1]\n",
    "feature_columns = [f'quantity{i//2 + 1}' if i % 2 == 0 else f'price{i//2 + 1}' for i in range(num_features)]\n",
    "centers_df = pd.DataFrame(final_centers, columns=feature_columns)\n",
    "centers_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8945249c-6e47-430b-9439-d571acf9802f",
   "metadata": {},
   "source": [
    "### Visualize curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66774395-c734-4a5c-bfc5-3a0aeb56f211",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Plotting parameters\n",
    "thick_line_width = 4\n",
    "thin_line_width = 1.0\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "# Get a color map\n",
    "color_map = plt.get_cmap('tab10')\n",
    "\n",
    "# Plotting cluster centers from 'centers_df' as thick lines\n",
    "for index, center_row in centers_df.iterrows():\n",
    "    cumulative_quantity, price = center_row.values.reshape(-1, 2).T\n",
    "    plt.step(cumulative_quantity, price, where='pre', linewidth=thick_line_width, label=f'Cluster Medoid {index}', color=color_map(index / len(centers_df)))\n",
    "\n",
    "# Plotting step-wise bid curves from 'df_subset_copy' as thinner lines\n",
    "for index, row in df_subset_copy.iterrows():\n",
    "    cluster_no = row['cluster_no']\n",
    "    cumulative_quantity, price = row[['quantity1', 'price1', 'quantity2', 'price2', 'quantity3', 'price3', 'quantity4', 'price4', 'quantity5', 'price5', 'quantity6', 'price6', 'quantity7', 'price7', 'quantity8', 'price8', 'quantity9', 'price9', 'quantity10', 'price10', 'quantity11', 'price11']].values.reshape(-1, 2).T\n",
    "    plt.step(cumulative_quantity, price, where='pre', linewidth=thin_line_width, linestyle='--', color=color_map(cluster_no / len(centers_df)))\n",
    "\n",
    "# Plotting settings\n",
    "plt.xlabel('Cumulative Quantity (MW)')\n",
    "plt.ylabel('Price (Peso/Megawatt-hr)')\n",
    "plt.title('Cluster Centers and Step-wise Bid Curves')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "821ae5ef-ebdb-403f-b376-295c4f4575ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Plotting parameters\n",
    "thick_line_width = 4\n",
    "thin_line_width = 1.0\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "# Get a color map\n",
    "color_map = plt.get_cmap('tab10')\n",
    "\n",
    "# Plotting cluster centers from 'centers_df' as thick lines\n",
    "for index, center_row in centers_df.iterrows():\n",
    "    cumulative_quantity, price = center_row.values.reshape(-1, 2).T\n",
    "    plt.step(cumulative_quantity, price, where='pre', linewidth=thick_line_width, label=f'Cluster Medoid {index}', color=color_map(index / len(centers_df)))\n",
    "\n",
    "# Plotting step-wise bid curves from 'df_subset' as thinner lines\n",
    "for index, row in df_subset.iterrows():\n",
    "    cluster_no = row['cluster_no']\n",
    "    cumulative_quantity, price = row[['quantity1', 'price1', 'quantity2', 'price2', 'quantity3', 'price3', 'quantity4', 'price4', 'quantity5', 'price5', 'quantity6', 'price6', 'quantity7', 'price7', 'quantity8', 'price8', 'quantity9', 'price9', 'quantity10', 'price10', 'quantity11', 'price11']].values.reshape(-1, 2).T\n",
    "    plt.step(cumulative_quantity, price, where='pre', linewidth=thin_line_width, linestyle='--', color=color_map(cluster_no / len(centers_df)))\n",
    "\n",
    "# Plotting settings\n",
    "plt.xlabel('Cumulative Quantity (MW)')\n",
    "plt.ylabel('Price (Peso/Megawatt-hr)')\n",
    "plt.title('Cluster Centers and Step-wise Bid Curves')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2169aaed-dad4-4d8f-b963-5b2f6c75527d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_subset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f06a32-0259-4c16-a45c-522617c8affa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Assuming 'centers_df' is your DataFrame\n",
    "for i in range(len(centers_df)):\n",
    "    cumulative_quantity, price = zip(*centers_df.iloc[i].values.reshape(-1, 2))\n",
    "    plt.step(cumulative_quantity, price, where='pre', label=f'Center {i + 1}')\n",
    "\n",
    "plt.xlabel('Quantity (MW)')\n",
    "plt.ylabel('Price (Peso/Megawatt-hr)')\n",
    "plt.title('Bid Curves for Cluster Centers')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e0b2a2e-a639-4ee6-9e78-4834fcbccf40",
   "metadata": {
    "tags": []
   },
   "source": [
    "# K-medoids on entire 2022 df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5cd0f6f-d49c-4fa3-9e34-293d8f27bc53",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Select only the first 100 entries from df_2022\n",
    "df_subset = df_2022.head(7948)\n",
    "\n",
    "# Get values from columns\n",
    "prices = df_subset[['price1', 'price2', 'price3', 'price4', 'price5', 'price6', 'price7', 'price8', 'price9', 'price10', 'price11']].values\n",
    "quantities = df_subset[['quantity1', 'quantity2', 'quantity3', 'quantity4', 'quantity5', 'quantity6', 'quantity7', 'quantity8', 'quantity9', 'quantity10', 'quantity11']].values\n",
    "\n",
    "# Function to create step-wise bid curves\n",
    "def create_stepwise_curves(prices, quantities):\n",
    "    step_curves = []\n",
    "    for i in range(len(prices)):\n",
    "        step_curves.append(list(zip(quantities[i], prices[i])))\n",
    "    return step_curves\n",
    "\n",
    "step_curves = create_stepwise_curves(prices, quantities)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d45f529-e988-4dd8-b7cc-020e6ccee288",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_curves = len(step_curves)\n",
    "length_of_first_curve = len(step_curves[0]) if num_curves > 0 else 0\n",
    "\n",
    "print(f\"Number of curves: {num_curves}\")\n",
    "print(f\"Length of the first curve: {length_of_first_curve}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478a2398-fd71-42e7-a630-e0f7a219b68f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Test Plot random indices\n",
    "# Randomly select 10 indices\n",
    "random_indices = df_subset.sample(n=10).index\n",
    "\n",
    "# Extract prices and cumulative quantities for the randomly selected indices\n",
    "selected_prices = df_subset.loc[random_indices, 'price1':'price11'].values\n",
    "selected_cumulative_quantities = df_subset.loc[random_indices, 'quantity1':'quantity11'].values\n",
    "\n",
    "# Plotting the selected step-wise bid curves\n",
    "for i, idx in enumerate(random_indices):\n",
    "    cumulative_quantity = selected_cumulative_quantities[i]\n",
    "    price = selected_prices[i]\n",
    "    plt.step(cumulative_quantity, price, where='pre', label=f'Curve {idx}')\n",
    "\n",
    "plt.xlabel('Cumulative Quantity (MW)')\n",
    "plt.ylabel('Price (Peso/Megawatt-hr)')\n",
    "plt.title('Randomly Selected Step-wise Bid Curves from df_subset')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd9849d-4a0d-4da8-b7ce-341e2a5bd08c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Display the subset of df_subset for the randomly selected indices\n",
    "df_subset_random = df_subset.loc[random_indices]\n",
    "df_subset_random.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668ad0b1-450f-4038-a4ee-3e9f1c2fb866",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Change step_curves into numpy array\n",
    "step_curves_array = np.array(step_curves).reshape(len(step_curves), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a0b11a-959d-4ca4-a37d-7490939bca76",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Shape of step_curves_array:\", step_curves_array.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd2422c1-5df6-46c2-a1b8-22088ed07b0e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b0f833-4831-4a7b-8922-8da20c53f8d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn_extra.cluster import KMedoids\n",
    "from scipy.stats import wasserstein_distance\n",
    "from tqdm.notebook import tqdm\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "# Function to calculate Wasserstein distance\n",
    "def wasserstein_dist(p1, p2):\n",
    "    return wasserstein_distance(p1, p2)\n",
    "\n",
    "# Function to perform K-medoids clustering\n",
    "def kmedoids_clustering(data, k):\n",
    "    kmedoids = KMedoids(n_clusters=k, metric=wasserstein_dist, random_state=42)\n",
    "    kmedoids.fit(data)\n",
    "    return kmedoids.labels_, kmedoids.cluster_centers_\n",
    "\n",
    "# Function to calculate Separation Threshold\n",
    "def separation_threshold_ratio(labels, centers, theta_0, p_ref):\n",
    "    k = len(centers)\n",
    "    s_ref = wasserstein_dist(centers[0], p_ref)  # Assuming P_ref is the first center\n",
    "    s_th = theta_0 * s_ref\n",
    "    \n",
    "    for i in range(k):\n",
    "        distances_within_cluster = [\n",
    "            wasserstein_dist(step_curves_array[j], centers[i]) \n",
    "            for j in range(len(labels)) if labels[j] == i\n",
    "        ]\n",
    "        rho_i = sum(1 for dist in distances_within_cluster if dist > s_th) / len(distances_within_cluster)\n",
    "\n",
    "        if rho_i > RHO_0:\n",
    "            return True\n",
    "\n",
    "    return False\n",
    "\n",
    "# Function to process a chunk\n",
    "def process_chunk(K):\n",
    "    labels, centers = kmedoids_clustering(step_curves_array, K)\n",
    "    print(f\"Processed chunk for K={K}: Labels: {labels}, Centers Shape: {np.shape(centers)}\")\n",
    "\n",
    "    # Check for empty clusters\n",
    "    empty_clusters = [i for i, cluster_size in enumerate(np.bincount(labels)) if cluster_size == 0]\n",
    "    if empty_clusters:\n",
    "        print(f\"Warning: Empty clusters found for K={K}, Cluster indices: {empty_clusters}\")\n",
    "\n",
    "    # Add more debugging information or checks as needed\n",
    "\n",
    "    return separation_threshold_ratio(labels, centers, THETA_0, P_ref), centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92693cf5-07c7-4bc8-95b7-614a3d9dfd02",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "K_0 = 2\n",
    "K_max = 7  # Choose a smaller value for testing\n",
    "THETA_0 = 0.01  # 1% as THETA_0\n",
    "RHO_0 = 0.075 #original was 0.1\n",
    "\n",
    "# Initial chunk size\n",
    "initial_chunk_size = 5000\n",
    "# Number of iterations within each chunk\n",
    "iterations_within_chunk = 500\n",
    "\n",
    "# Reduce memory usage\n",
    "step_curves_array = step_curves_array.astype(np.float32)\n",
    "\n",
    "# Initialization\n",
    "K = K_0\n",
    "P_ref = step_curves_array[0]  # Using the first curve as a reference\n",
    "\n",
    "# Initialize the variable to track the optimal number of clusters\n",
    "optimal_K = K_0  \n",
    "\n",
    "# Store cluster centers and labels here\n",
    "centers_list = []  \n",
    "labels_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5427f2-5a06-4388-8ab2-46f34d23ebed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "with tqdm(total=K_max - K_0 + 1, desc=\"Iterating through K clusters\") as pbar:\n",
    "    while K <= K_max:  \n",
    "        pbar.set_postfix({\"Current K\": K})\n",
    "\n",
    "        # Dynamic chunk size based on remaining clusters\n",
    "        remaining_clusters = K_max - K\n",
    "        chunk_size = min(initial_chunk_size, remaining_clusters)\n",
    "\n",
    "        print(f\"Processing chunk for K={K}\")\n",
    "\n",
    "        result_found = False  # Flag to track whether a result was found in the inner loop\n",
    "\n",
    "        for _ in range(iterations_within_chunk):\n",
    "            # Use `list()` to force the progress bar to update in a Jupyter Notebook\n",
    "            chunk_results = list(Parallel(n_jobs=-1)(delayed(process_chunk)(K + i) for i in range(chunk_size)))\n",
    "\n",
    "            for result, centers in chunk_results:\n",
    "                if result:\n",
    "                    optimal_K = K  # Update the optimal_K variable\n",
    "                    centers_list.append(centers)\n",
    "                    labels_list.append(kmedoids_clustering(step_curves_array, K)[0])\n",
    "                    result_found = True\n",
    "                    break\n",
    "\n",
    "            if result_found:\n",
    "                break  # Break out of the inner loop if a result is found\n",
    "\n",
    "            pbar.update(1)  \n",
    "\n",
    "            # Print additional information every 100 iterations\n",
    "            if K % 100 == 0:\n",
    "                print(f\"Current iteration: {K}, Result: {result}\")\n",
    "\n",
    "        if result_found:\n",
    "            break  # Break out of the outer loop if a result is found\n",
    "\n",
    "        # Increment K after the chunk is processed\n",
    "        K += chunk_size\n",
    "\n",
    "# Now optimal_K contains the optimal number of clusters, up to K_max\n",
    "print(f\"Optimal number of clusters (K): {optimal_K}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c195fb1-4bc0-444b-865e-bbbc5c839ad9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "labels_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ebf6916-3002-451b-8fc6-71bcfb593d71",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Assuming 'labels_list' is your list of labels after K-means clustering\n",
    "cluster_labels = labels_list[0]\n",
    "\n",
    "# Add 'cluster_no' column to df_subset using .loc\n",
    "df_subset.loc[:, 'cluster_no'] = cluster_labels\n",
    "df_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea319fdc-b76c-4469-8113-455a71d2ba5d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Assuming 'centers_list' is your list of cluster centers\n",
    "final_centers = centers_list[-1]\n",
    "\n",
    "# Assuming 'final_centers' is your cluster centers\n",
    "num_features = final_centers.shape[1]\n",
    "feature_columns = [f'quantity{i//2 + 1}' if i % 2 == 0 else f'price{i//2 + 1}' for i in range(num_features)]\n",
    "centers_df = pd.DataFrame(final_centers, columns=feature_columns)\n",
    "centers_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c16a1ac-4d43-4837-943d-9ac741012ab6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_subset.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938ef3ee-dfa4-4bd0-949c-b42c4ddab9a1",
   "metadata": {},
   "source": [
    "### Visualize curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d30ef24-ea1d-49e2-9206-29237dd6d9e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Plotting parameters\n",
    "thick_line_width = 5\n",
    "thin_line_width = 0.5\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "# Get a color map\n",
    "color_map = plt.get_cmap('tab10')\n",
    "\n",
    "# Plotting step-wise bid curves from 'df_subset' as thinner lines\n",
    "for index, row in df_subset.iterrows():\n",
    "    cluster_no = row['cluster_no']\n",
    "    cumulative_quantity, price = row[['quantity1', 'price1', 'quantity2', 'price2', 'quantity3', 'price3', 'quantity4', 'price4', 'quantity5', 'price5', 'quantity6', 'price6', 'quantity7', 'price7', 'quantity8', 'price8', 'quantity9', 'price9', 'quantity10', 'price10', 'quantity11', 'price11']].values.reshape(-1, 2).T\n",
    "    plt.step(cumulative_quantity, price, where='pre', linewidth=thin_line_width, linestyle='--', color=color_map(cluster_no / len(centers_df)))\n",
    "\n",
    "# Plotting cluster centers from 'centers_df' as thick lines\n",
    "for index, center_row in centers_df.iterrows():\n",
    "    cumulative_quantity, price = center_row.values.reshape(-1, 2).T\n",
    "    plt.step(cumulative_quantity, price, where='pre', linewidth=thick_line_width, label=f'Cluster Medoid {index}', color=color_map(index / len(centers_df)))\n",
    "\n",
    "# Plotting settings\n",
    "plt.xlabel('Cumulative Quantity (MW)')\n",
    "plt.ylabel('Price (Peso/Megawatt-hr)')\n",
    "plt.title('Cluster Centers and Step-wise Bid Curves')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a924b7d-0251-4117-a837-c9210d1617fe",
   "metadata": {
    "tags": []
   },
   "source": [
    "# [WIP] K-medoids with both Price-Quantity Scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61bbeaab-8a0c-4f6e-b2c0-4a0be8d10580",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Select only the first 100 entries from df_2022\n",
    "df_subset = df_2022.head(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318f7c2d-018b-4f6a-aca3-364ab42284c8",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get values from columns\n",
    "prices = df_subset[['price1', 'price2', 'price3', 'price4', 'price5', 'price6', 'price7', 'price8', 'price9', 'price10', 'price11']].values\n",
    "quantities = df_subset[['quantity1', 'quantity2', 'quantity3', 'quantity4', 'quantity5', 'quantity6', 'quantity7', 'quantity8', 'quantity9', 'quantity10', 'quantity11']].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a85210-e837-47c6-bee2-c7466cc279f4",
   "metadata": {},
   "source": [
    "## RobustScaler on Price values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef99f20-7050-4ef9-8616-684be6f072f3",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "# # Assuming prices is a DataFrame with columns price1 to price11\n",
    "# prices_columns = [f'price{i}' for i in range(1, 12)]\n",
    "# prices = df_subset[prices_columns]\n",
    "\n",
    "# Apply Robust scaling to prices\n",
    "scaler_prices = RobustScaler()\n",
    "prices_scaled = scaler_prices.fit_transform(prices)\n",
    "prices_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa0d8a8-6a0c-4c80-82a7-52692efb686a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# statistics\n",
    "\n",
    "prices_scaled_stats = {\n",
    "    'mean': np.mean(prices_scaled, axis=0),\n",
    "    'std': np.std(prices_scaled, axis=0),\n",
    "    'min': np.min(prices_scaled, axis=0),\n",
    "    '25%': np.percentile(prices_scaled, 25, axis=0),\n",
    "    '50%': np.percentile(prices_scaled, 50, axis=0),\n",
    "    '75%': np.percentile(prices_scaled, 75, axis=0),\n",
    "    'max': np.max(prices_scaled, axis=0),\n",
    "}\n",
    "\n",
    "# Create a DataFrame for better visualization\n",
    "prices_scaled_stats_df = pd.DataFrame(prices_scaled_stats, index=[f'Price_{i+1}' for i in range(prices_scaled.shape[1])])\n",
    "\n",
    "# Display the statistics DataFrame\n",
    "print(prices_scaled_stats_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8745de49-bd9b-481a-b499-1f4ff12b4ab5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Specify the desired range based on your data\n",
    "desired_range = (-10, 10)\n",
    "\n",
    "# Flatten the 2D array into a 1D array\n",
    "scaled_prices_flat = prices_scaled.flatten()\n",
    "\n",
    "# Plot histogram with specified range\n",
    "plt.hist(scaled_prices_flat, bins=20, range=desired_range, color='blue', alpha=0.7)\n",
    "plt.xlabel('Scaled Prices')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Scaled Prices')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e48dd5d-4818-4f61-87c2-4ac66fd085b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Assuming 'prices_scaled' is your array\n",
    "sns.set(style=\"whitegrid\")\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Create a box plot to visualize the distribution\n",
    "sns.boxplot(data=prices_scaled, orient=\"v\", palette=\"Set2\")\n",
    "\n",
    "plt.title('Box Plot of Scaled Prices')\n",
    "plt.ylabel('Scaled Prices')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f4e65b5-39f7-4db9-ab69-6786e0e52c7f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Using prices_scaled\n",
    "def create_stepwise_curves_scaled(prices, quantities):\n",
    "    step_curves = []\n",
    "    for i in range(len(prices)):\n",
    "        step_curves.append(list(zip(quantities[i], prices[i])))\n",
    "    return step_curves\n",
    "\n",
    "# Create list of lists containting price,quantity tuples\n",
    "step_curves = create_stepwise_curves_scaled(prices_scaled, quantities)\n",
    "step_curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35007c49-0d1f-4ead-a47a-40084c1af6de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_curves = len(step_curves)\n",
    "length_of_first_curve = len(step_curves[0]) if num_curves > 0 else 0\n",
    "\n",
    "print(f\"Number of curves: {num_curves}\")\n",
    "print(f\"Length of the first curve: {length_of_first_curve}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbbe25e6-7b63-47a2-967f-3012553aaa5a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Test Plot random indices\n",
    "# Randomly select 10 indices\n",
    "random_indices = df_subset.sample(n=10).index\n",
    "\n",
    "# Extract prices and cumulative quantities for the randomly selected indices\n",
    "selected_prices = df_subset.loc[random_indices, 'price1':'price11'].values\n",
    "selected_cumulative_quantities = df_subset.loc[random_indices, 'quantity1':'quantity11'].values\n",
    "\n",
    "# Plotting the selected step-wise bid curves\n",
    "for i, idx in enumerate(random_indices):\n",
    "    cumulative_quantity = selected_cumulative_quantities[i]\n",
    "    price = selected_prices[i]\n",
    "    plt.step(cumulative_quantity, price, where='pre', label=f'Curve {idx}')\n",
    "\n",
    "plt.xlabel('Cumulative Quantity (MW)')\n",
    "plt.ylabel('Price (Peso/Megawatt-hr)')\n",
    "plt.title('Randomly Selected Step-wise Bid Curves from df_subset')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4920d8e9-9aa3-452e-9116-0c5930f13904",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Display the subset of df_subset for the randomly selected indices\n",
    "df_subset_random = df_subset.loc[random_indices]\n",
    "# df_subset_random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d8b17c-ce45-451e-a140-da34f209fb3e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Change step_curves into 2D numpy array \n",
    "step_curves_array = np.array(step_curves).reshape(len(step_curves), -1)\n",
    "step_curves_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4f95c2-eb76-4c3a-a0bd-f4dced9a253f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Shape of step_curves_array:\", step_curves_array.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1483fcdf-9af6-4435-a491-d2f48f8ea4eb",
   "metadata": {
    "tags": []
   },
   "source": [
    "## K-medoids Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c39bc0c7-8ad4-4f88-9525-fb3abec2135f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn_extra.cluster import KMedoids\n",
    "from scipy.stats import wasserstein_distance\n",
    "from joblib import Parallel, delayed\n",
    "import numpy as np\n",
    "\n",
    "# Function to calculate Wasserstein distance\n",
    "def wasserstein_dist(p1, p2):\n",
    "    return wasserstein_distance(p1, p2)\n",
    "\n",
    "# Function to perform K-medoids clustering\n",
    "def kmedoids_clustering(data, k):\n",
    "    kmedoids = KMedoids(n_clusters=k, metric=wasserstein_dist, random_state=42)\n",
    "    kmedoids.fit(data)\n",
    "    return kmedoids.labels_, kmedoids.cluster_centers_\n",
    "\n",
    "# Function to calculate Separation Threshold\n",
    "def calculate_separation_threshold(labels, centers, separation_threshold, p_ref):\n",
    "    k = len(centers)\n",
    "    s_ref = wasserstein_dist(centers[0], p_ref)  # Assuming P_ref is the first center\n",
    "    s_th = separation_threshold * s_ref\n",
    "    \n",
    "    for i in range(k):\n",
    "        distances_within_cluster = [\n",
    "            wasserstein_dist(step_curves_array[j], centers[i]) \n",
    "            for j in range(len(labels)) if labels[j] == i\n",
    "        ]\n",
    "        rho_i = sum(1 for dist in distances_within_cluster if dist > s_th) / len(distances_within_cluster)\n",
    "\n",
    "        if rho_i > tolerance_rate:\n",
    "            return True\n",
    "\n",
    "    return False\n",
    "\n",
    "# Modify process_chunk to return labels along with result\n",
    "def process_chunk(K, step_curves_array, separation_threshold, tolerance_rate):\n",
    "    labels, centers = kmedoids_clustering(step_curves_array, K)\n",
    "    print(f\"Processed chunk for K={K}: Labels: {labels}, Centers Shape: {np.shape(centers)}\")\n",
    "\n",
    "    # Check for empty clusters\n",
    "    empty_clusters = [i for i, cluster_size in enumerate(np.bincount(labels)) if cluster_size == 0]\n",
    "    if empty_clusters:\n",
    "        print(f\"Warning: Empty clusters found for K={K}, Cluster indices: {empty_clusters}\")\n",
    "\n",
    "    # Print debugging information\n",
    "    print(\"Cluster Centers:\")\n",
    "    print(centers)\n",
    "\n",
    "    result = calculate_separation_threshold(labels, centers, separation_threshold, step_curves_array[0])\n",
    "\n",
    "    return result, labels, centers\n",
    "\n",
    "\n",
    "# Function to find optimal number of clusters\n",
    "def find_optimal_clusters(step_curves_array, K_0, K_max, initial_chunk_size, iterations_within_chunk, separation_threshold, tolerance_rate):\n",
    "    step_curves_array = step_curves_array.astype(np.float32)\n",
    "    \n",
    "    # Initialization\n",
    "    K = K_0\n",
    "    P_ref = step_curves_array[0]  # Using the first curve as a reference\n",
    "\n",
    "    # Initialize the variable to track the optimal number of clusters\n",
    "    optimal_K = K_0  \n",
    "\n",
    "    # Store cluster centers and labels here\n",
    "    centers_list = []  \n",
    "    labels_list = []\n",
    "\n",
    "    while K <= K_max:  \n",
    "        print(f\"Processing chunk for K={K}\")\n",
    "\n",
    "        result_found = False  # Flag to track whether a result was found in the inner loop\n",
    "        # Inside your loop in find_optimal_clusters function\n",
    "        for _ in range(iterations_within_chunk):\n",
    "            chunk_size = min(initial_chunk_size, K_max - K)\n",
    "            chunk_results = list(Parallel(n_jobs=-1)(delayed(process_chunk)(K + i, step_curves_array, separation_threshold, tolerance_rate) for i in range(chunk_size)))\n",
    "\n",
    "            for result, labels, centers in chunk_results:\n",
    "                if result:\n",
    "                    optimal_K = K  # Update the optimal_K variable\n",
    "                    centers_list.append(centers)\n",
    "                    labels_list.append(labels)\n",
    "                    result_found = True\n",
    "                    break\n",
    "\n",
    "            if result_found:\n",
    "                break  # Break out of the inner loop if a result is found\n",
    "                \n",
    "        if result_found:\n",
    "            break  # Break out of the outer loop if a result is found\n",
    "\n",
    "        # Increment K after the chunk is processed\n",
    "        K += chunk_size\n",
    "\n",
    "    # Now optimal_K contains the optimal number of clusters, up to K_max\n",
    "    print(f\"Optimal number of clusters (K): {optimal_K}\")\n",
    "    \n",
    "    # Return the labels_list\n",
    "    return labels_list, centers_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d909ab7a-35b5-4100-a42e-6ff60ac215d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Parameters\n",
    "K_0 = 2\n",
    "K_max = 4  # Choose a smaller value for testing\n",
    "separation_threshold = 0.01  # 1% as separation_threshold_ratio, increase if you think clusters should have larger dissimilarity\n",
    "tolerance_rate = 0.05  # original was 0.1, increase if you want to be more strict about considering a cluster as separate\n",
    "\n",
    "# Initial chunk size\n",
    "initial_chunk_size = 8000\n",
    "# Number of iterations within each chunk\n",
    "iterations_within_chunk = 500\n",
    "\n",
    "# Find optimal clusters\n",
    "found_labels_list, found_centers_list = find_optimal_clusters(step_curves_array, K_0, K_max, initial_chunk_size, iterations_within_chunk, separation_threshold, tolerance_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296d9a1e-2e4b-4935-b3e9-03d6e675f3c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Assuming 'found_labels_list' is your list of labels after clustering\n",
    "cluster_labels = found_labels_list[0]\n",
    "\n",
    "# Add 'cluster_no' column to df_subset using .loc\n",
    "df_subset.loc[:, 'cluster_no'] = cluster_labels.copy()  # Use .copy() to avoid the warning\n",
    "df_subset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa46ebb-34d4-4bc0-a52b-11ccb10ff824",
   "metadata": {},
   "source": [
    "## Reconstitute centers df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f030ea-2667-4a9f-90d9-f8909eabd353",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "found_centers_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845800c7-fd49-40b7-bb90-88576e401aff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming 'step_curves_array' is your original data for scaling\n",
    "num_features = len(step_curves[0][0])  # Assuming each step has 'num_features' features\n",
    "price_indices = range(1, num_features * len(step_curves[0]), num_features)\n",
    "\n",
    "# Calculate min and max prices\n",
    "min_prices = step_curves_array[:, price_indices].min(axis=0)\n",
    "max_prices = step_curves_array[:, price_indices].max(axis=0)\n",
    "max_prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a93ff5-1b79-4b1c-989e-ac86331475e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to inverse scale prices\n",
    "def inverse_scale_prices(scaled_prices, min_prices, max_prices):\n",
    "    return (scaled_prices * (max_prices - min_prices)) + min_prices\n",
    "\n",
    "# Create an empty DataFrame for centers_df\n",
    "centers_df = pd.DataFrame()\n",
    "\n",
    "# Iterate over the clusters and inverse scale prices\n",
    "for i, cluster_center in enumerate(found_centers_list):\n",
    "    # Assuming 'found_centers_list' is a list of numpy arrays for each cluster center\n",
    "    center_df = pd.DataFrame(cluster_center, columns=[f'quantity{i+1}', f'price{i+1}'])\n",
    "\n",
    "    # Inverse scale prices for the current cluster\n",
    "    center_df[f'price{i+1}'] = inverse_scale_prices(center_df[f'price{i+1}'], min_prices, max_prices)\n",
    "\n",
    "    # Concatenate to the overall centers_df\n",
    "    centers_df = pd.concat([centers_df, center_df], axis=1)\n",
    "\n",
    "# Display the final DataFrame\n",
    "centers_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
